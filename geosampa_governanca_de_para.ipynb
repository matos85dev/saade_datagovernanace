{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69127518-2a82-40ea-9e58-5d74eb7f7815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b66151da-dce9-4fe6-95a1-db20711e2660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import httpx\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "from tenacity import before_sleep_log, retry, retry_if_exception_type, stop_after_attempt, wait_random_exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a1ddbbd-c05d-4821-a9aa-4a1047a8ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import JSONDecodeError\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95283d5d-dc8d-4432-a10f-b02b062654bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests.exceptions import HTTPError\n",
    "\n",
    "class ResponseNotJson(HTTPError):\n",
    "    '''Raised when the response is not a JSON'''\n",
    "\n",
    "class ResponseNotXML(HTTPError):\n",
    "    '''Raised when the response is not a XML'''\n",
    "\n",
    "class PaginationError(HTTPError):\n",
    "    '''Raised hen total retrieved features is not equal to total features returned by API'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89f8951a-7c4e-48e3-a2c2-646e92054d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raise_for_status(func):\n",
    "    '''Raises HTTP error for response status codes 4xx or 5xx.\n",
    "    If not, returns content of response'''\n",
    "\n",
    "    def decorated(*args, **kwargs):\n",
    "\n",
    "        response = func(*args, **kwargs)\n",
    "        response.raise_for_status()\n",
    "        content = response.content\n",
    "\n",
    "        return content\n",
    "\n",
    "    return decorated\n",
    "\n",
    "\n",
    "def json_response(func):\n",
    "    '''Parses json response. Raises xml string error if\n",
    "    xml is returned'''\n",
    "\n",
    "    def decorated(*args, **kwargs):\n",
    "\n",
    "        response = func(*args, **kwargs)\n",
    "        json_txt = response.decode('utf-8')\n",
    "        try:\n",
    "            json_data = json.loads(json_txt)\n",
    "            return json_data\n",
    "        except JSONDecodeError:\n",
    "            response = xmltodict.parse(response)\n",
    "            raise ResponseNotJson(f'Response is not a JSON: {response}')\n",
    "    \n",
    "    return decorated\n",
    "\n",
    "def xml_response(func):\n",
    "    '''Parses xml response as a dict'''\n",
    "\n",
    "    def decorated(*args, **kwargs):\n",
    "        \n",
    "        try:\n",
    "            response = func(*args, **kwargs)\n",
    "            parsed = xmltodict.parse(response)\n",
    "            return parsed\n",
    "        except Exception as e:\n",
    "            raise ResponseNotXML(f'XML parsing failed {e}')\n",
    "    \n",
    "    return decorated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54a036ec-75de-4e49-aa66-970607122a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class BaseClient:\n",
    "    \"\"\"WFS base client - used to make generic requests\"\"\"\n",
    "\n",
    "    accepted_versions = {\"2.0.0\"}\n",
    "    output_formats = {\"json\", \"xml\", \"bytes\"}\n",
    "\n",
    "    def __init__(self, domain: str, version: str = \"2.0.0\", verbose: bool = True):\n",
    "        self.domain = self.__clean_domain(domain)\n",
    "        self.version = self.__assert_version(version)\n",
    "        self.host = self.__gen_host()\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def __clean_domain(self, domain: str) -> str:\n",
    "        if domain.endswith(r\"/\"):\n",
    "            domain = domain[:-1]\n",
    "\n",
    "        return domain\n",
    "\n",
    "    def __assert_version(self, version: str) -> str:\n",
    "        if version not in self.accepted_versions:\n",
    "            raise ValueError(f\"Accepted versions: {self.accepted_versions}\")\n",
    "        return version\n",
    "\n",
    "    def __gen_host(self) -> str:\n",
    "        wfs_version = f\"/?service=WFS&version={self.version}\"\n",
    "        return self.domain + wfs_version\n",
    "\n",
    "    def __solve_get_params(self, *ignore, **query_params: dict) -> str:\n",
    "        request_args = [\"=\".join([param_name, str(param_value)]) for param_name, param_value in query_params.items()]\n",
    "        query_string = \"&\".join(request_args)\n",
    "\n",
    "        return query_string\n",
    "\n",
    "    def __solve_req_capability(self, capability: str) -> str:\n",
    "        capability_param = f\"request={capability}\"\n",
    "\n",
    "        return capability_param\n",
    "\n",
    "    def __solve_request_url(self, capability: str, **query_params: dict) -> str:\n",
    "        base_url = self.host\n",
    "        capability_param = self.__solve_req_capability(capability)\n",
    "        url = base_url + \"&\" + capability_param\n",
    "\n",
    "        if query_params is None:\n",
    "            return url\n",
    "        else:\n",
    "            req_params = self.__solve_get_params(**query_params)\n",
    "            return url + \"&\" + req_params\n",
    "\n",
    "    @retry(\n",
    "        retry=retry_if_exception_type(RequestException),\n",
    "        stop=stop_after_attempt(10),\n",
    "        wait=wait_random_exponential(5, min=5, max=60),\n",
    "        before_sleep=before_sleep_log(logger, logging.INFO, exc_info=True),\n",
    "    )\n",
    "    @raise_for_status\n",
    "    def wfs_generic_request(self, capability: str, *ignore, **query_params: dict) -> bytes:\n",
    "        url = self.__solve_request_url(capability, **query_params)\n",
    "\n",
    "        # response is in bytes, so must be decoed accordingly\n",
    "        with requests.get(url) as response:\n",
    "            return response\n",
    "\n",
    "    async def wfs_async_requests(self, capability: str, pages, **query_params: dict):\n",
    "        params = query_params.copy()\n",
    "        async with httpx.AsyncClient() as client:\n",
    "\n",
    "            @retry(\n",
    "                retry=retry_if_exception_type(httpx.HTTPError),\n",
    "                stop=stop_after_attempt(10),\n",
    "                wait=wait_random_exponential(30, min=30, max=300),\n",
    "                before_sleep=before_sleep_log(logger, logging.INFO, exc_info=True),\n",
    "            )\n",
    "            async def fetch(url, semaphore):\n",
    "                async with semaphore:\n",
    "                    response = await client.get(url, timeout=300)\n",
    "                    response.raise_for_status()\n",
    "                    return response\n",
    "\n",
    "            tasks = []\n",
    "            semaphore = asyncio.Semaphore(4)\n",
    "\n",
    "            for page in pages:\n",
    "                params[\"startIndex\"] = page\n",
    "                url = self.__solve_request_url(capability, **params)\n",
    "                task = asyncio.create_task(fetch(url, semaphore))\n",
    "                tasks.append(task)\n",
    "\n",
    "            responses = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "        for response in responses:\n",
    "            if isinstance(response, Exception):\n",
    "                # Handle exceptions\n",
    "                print(f\"Request failed: {response}\")\n",
    "\n",
    "        @json_response\n",
    "        def parse_response(response):\n",
    "            return response.content\n",
    "\n",
    "        responses = [parse_response(response) for response in responses]\n",
    "\n",
    "        first_response = responses[0]\n",
    "        for response in responses[1:]:\n",
    "            first_response[\"features\"].extend(response[\"features\"])\n",
    "\n",
    "        return first_response\n",
    "\n",
    "    @json_response\n",
    "    def get_json(self, capability: str, **query_params: dict) -> dict:\n",
    "        return self.wfs_generic_request(\n",
    "            capability, outputFormat=\"application/json\", exceptions=\"application/json\", **query_params\n",
    "        )\n",
    "\n",
    "    @xml_response\n",
    "    def get_xml(self, capability: str, **query_params: dict) -> dict:\n",
    "        return self.wfs_generic_request(capability, **query_params)\n",
    "\n",
    "    def __call__(self, capability: str, *ignore, output_format=\"json\", pages=None, **query_params: dict) -> bytes:\n",
    "        if output_format not in self.output_formats:\n",
    "            raise ValueError(f\"output_format must be in {self.output_formats}\")\n",
    "\n",
    "        if output_format == \"json\":\n",
    "            return self.get_json(capability, **query_params)\n",
    "\n",
    "        elif output_format == \"xml\":\n",
    "            return self.get_xml(capability, **query_params)\n",
    "\n",
    "        else:\n",
    "            return self.wfs_generic_request(capability, **query_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61e8838c-42de-45ea-8fba-db28a36a31b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "class CQLFilter:\n",
    "    '''Builds a CQL filter for querying the WFS server'''\n",
    "    \n",
    "    def __init__(self, feature_name:str, schema:dict)->None:\n",
    "        \n",
    "        self.feature_name = feature_name\n",
    "        self.schema = schema[feature_name]\n",
    "        self.cql_filter = ''\n",
    "        \n",
    "    def add_to_filter(self, query_str:str, sep:str=';')->None:\n",
    "        \n",
    "        if len(self.cql_filter)<1:\n",
    "            self.cql_filter=query_str\n",
    "        else:\n",
    "            query_str = sep + query_str\n",
    "            self.cql_filter += query_str\n",
    "    \n",
    "    def __check_propertie_in_schema(self, prop_name:str)->None:\n",
    "        \n",
    "        if prop_name not in self.schema:\n",
    "            raise ValueError(f'Feature name {prop_name} must be in {self.schema.keys()}')\n",
    "        \n",
    "    def __propertie_equals(self, propertie_name:str, equals_to:Union[str, int, float]):\n",
    "        \n",
    "        self.__check_propertie_in_schema(propertie_name)\n",
    "        if type(equals_to) is str:\n",
    "            equals_to = f\"'{equals_to}'\"\n",
    "\n",
    "        query_str = f\"({propertie_name}={equals_to})\"\n",
    "        \n",
    "        return query_str\n",
    "    \n",
    "    def properties_equals(self, *ignore, **propertie_comparisons):\n",
    "        \n",
    "        #se tiver mais de um filtro, separa corretamente\n",
    "        self.add_to_filter('', sep=';')\n",
    "        for prop_name, prop_val in propertie_comparisons.items():\n",
    "            query_str = self.__propertie_equals(prop_name, prop_val)\n",
    "            self.add_to_filter(query_str, sep='AND')\n",
    "\n",
    "    def point_within_pol(self, x:float, y:float, precision:int=5)->dict:\n",
    "        '''Precision is in meters. Returns the polygon in self.feature_name \n",
    "        which intersects a buffer of {precision} meters centralized at the point'''\n",
    "\n",
    "        query = f'DWITHIN(ge_poligono,POINT({x} {y}),{precision},meters)'\n",
    "        self.add_to_filter(query)\n",
    "\n",
    "    def point_within_linha(self, x:float, y:float, precision:int=5)->dict:\n",
    "        '''Precision is in meters. Returns the polygon in self.feature_name \n",
    "        which intersects a buffer of {precision} meters centralized at the point'''\n",
    "\n",
    "        query = f'DWITHIN(ge_linha,POINT({x} {y}),{precision},meters)'\n",
    "        self.add_to_filter(query)\n",
    "\n",
    "    def point_within_multipol(self, x:float, y:float, precision:int=5)->dict:\n",
    "        '''Precision is in meters. Returns the polygon in self.feature_name \n",
    "        which intersects a buffer of {precision} meters centralized at the point'''\n",
    "\n",
    "        query = f'DWITHIN(ge_multipoligono,POINT({x} {y}),{precision},meters)'\n",
    "        self.add_to_filter(query)\n",
    "\n",
    "    def polygon_within_pol(self, coordinates:str, precision:int=5)->dict:\n",
    "        '''Precision is in meters. Returns the polygon in self.feature_name \n",
    "        which intersects a buffer of {precision} meters centralized at the point'''\n",
    "\n",
    "        query = f'DWITHIN(ge_poligono,POLYGON({coordinates}),{precision},meters)'\n",
    "        self.add_to_filter(query)\n",
    "\n",
    "    def polygon_within_linha(self, coordinates:str, precision:int=5)->dict:\n",
    "        '''Precision is in meters. Returns the polygon in self.feature_name \n",
    "        which intersects a buffer of {precision} meters centralized at the point'''\n",
    "\n",
    "        query = f'DWITHIN(ge_linha,POLYGON({coordinates}),{precision},meters)'\n",
    "        self.add_to_filter(query)\n",
    "\n",
    "    def polygon_within_multipol(self, coordinates:str, precision:int=5)->dict:\n",
    "        '''Precision is in meters. Returns the polygon in self.feature_name \n",
    "        which intersects a buffer of {precision} meters centralized at the point'''\n",
    "\n",
    "        query = f'DWITHIN(ge_multipoligono,POLYGON({coordinates}),{precision},meters)'\n",
    "        self.add_to_filter(query)\n",
    "\n",
    "\n",
    "    def __call__(self):\n",
    "        \n",
    "        return self.cql_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22154223-d327-4fec-8d5d-62254ae69490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec25ada3-306d-4e9a-82d9-039d0ce0488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paginator:\n",
    "    def __init__(self, get_function: BaseClient, schemas: dict = None) -> None:\n",
    "        self.schemas = schemas or {}\n",
    "        self.get = get_function\n",
    "\n",
    "    def extract_total_features(self, resp: dict) -> int:\n",
    "        return resp[\"totalFeatures\"]\n",
    "\n",
    "    def extract_returned_quantity(self, resp: dict) -> int:\n",
    "        return len(resp[\"features\"])\n",
    "\n",
    "    def needs_pagination(self, total_features: int, returned_quantity: int) -> bool:\n",
    "        return total_features > returned_quantity\n",
    "\n",
    "    def get_steps(self, total_features: int, returned_quantity: int) -> list:\n",
    "        # need to start at zero because first query wans't ordered\n",
    "        return [step for step in range(0, total_features, returned_quantity)]\n",
    "\n",
    "    def warn_steps(self, feature_name: str, steps: list) -> None:\n",
    "        total_steps = len(steps)\n",
    "\n",
    "        warnings.warn(f\"Paginação iniciada. Serão realizadas {total_steps} requisições para a {feature_name}\")\n",
    "\n",
    "    def get_index_col(self, feature_name: str, index_col: str = None) -> str:\n",
    "        if index_col:\n",
    "            warnings.warn(f\"Certifique-se que a index_col de fato é uma coluna existente na feature\")\n",
    "            return index_col\n",
    "\n",
    "        if not self.schemas:\n",
    "            raise ValueError(f\"Must set schemas if willing to paginate and not specify index col\")\n",
    "\n",
    "        feature_schemas = self.schemas.get(feature_name, None)\n",
    "        if feature_schemas is None:\n",
    "            raise ValueError(f\"Schema for feature {feature_name} not found. Must specify index col\")\n",
    "\n",
    "        index_col = feature_schemas.get(\"id_col\")\n",
    "        if index_col is None:\n",
    "            raise ValueError(f\"Feature {feature_name} has no defaul index col. Must specify index col\")\n",
    "\n",
    "        return index_col\n",
    "\n",
    "    def paginate(self, feature_name: str, resp: dict, index_col: str = None, *_ignored, **query_params) -> dict:\n",
    "        total_features = self.extract_total_features(resp)\n",
    "        returned_quantity = self.extract_returned_quantity(resp)\n",
    "\n",
    "        if not self.needs_pagination(total_features, returned_quantity):\n",
    "            return resp\n",
    "\n",
    "        print(\"Paginação iniciada\")\n",
    "        index_col = self.get_index_col(feature_name, index_col)\n",
    "\n",
    "        steps = self.get_steps(total_features, returned_quantity)\n",
    "        self.warn_steps(feature_name, steps)\n",
    "\n",
    "        # recriando as features\n",
    "        resp[\"features\"] = []\n",
    "\n",
    "        for _ in steps:\n",
    "            resp_step = self.get(\"GetFeature\", typeName=feature_name, sortBy=index_col, **query_params)\n",
    "            features_step = resp_step[\"features\"]\n",
    "            resp[\"features\"].extend(features_step)\n",
    "            max_index = features_step[-1][\"properties\"][index_col]\n",
    "            query_params[\"cql_filter\"] = f\"{index_col}>{max_index}\"\n",
    "\n",
    "        total_returned_features = len(resp[\"features\"])\n",
    "        if not total_returned_features == total_features:\n",
    "            raise PaginationError(\n",
    "                f\"\"\"Difference in total features and paginated features: \n",
    "                          total - {total_features} vs returned - {total_returned_features}\n",
    "                          \"\"\"\n",
    "            )\n",
    "\n",
    "        return resp\n",
    "\n",
    "    def __call__(self, feature_name: str, resp: dict, index_col: str = None, *_ignored, **query_params) -> dict:\n",
    "        return self.paginate(feature_name, resp, index_col, **query_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90481101-53d9-4936-b655-a1d85033a37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from collections import OrderedDict\n",
    "\n",
    "class FeatureMdataParser:\n",
    "    '''Parses feature metadata'''\n",
    "\n",
    "    def parse_property(self, prop:dict)->dict:\n",
    "\n",
    "        name = prop['name']\n",
    "        parsed = dict(\n",
    "            nullable = prop['nillable'],\n",
    "            dtype = prop['localType']\n",
    "            )\n",
    "\n",
    "        return {name : parsed}\n",
    "    \n",
    "    def get_cd_identificador(self, prop:dict, cd_col_name:str='cd_identifica')->bool:\n",
    "\n",
    "        name = prop['name']\n",
    "        if name.lower().startswith(cd_col_name):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def set_cd_identificador(self, properties:dict, prop:dict)->None:\n",
    "\n",
    "        if self.get_cd_identificador(prop) and \\\n",
    "            not properties.get('id_col'):\n",
    "\n",
    "            properties['id_col'] = prop['name']\n",
    "\n",
    "    def parse_feature_schema(self, feat:dict)->dict:\n",
    "\n",
    "        name = feat['typeName']\n",
    "        properties = OrderedDict()\n",
    "        for prop in feat['properties']:\n",
    "            parsed_prop = self.parse_property(prop)\n",
    "            properties.update(parsed_prop)\n",
    "\n",
    "            self.set_cd_identificador(properties, prop)\n",
    "\n",
    "        parsed ={\n",
    "            name : properties\n",
    "        }\n",
    "\n",
    "        return parsed\n",
    "    \n",
    "    def raise_for_no_id(self, parsed_feature:dict)->None:\n",
    "\n",
    "        for feature_name, mdata in parsed_feature.items():\n",
    "            if 'id_col' not in mdata:\n",
    "                warnings.warn(f\"Could not identify id col for feature {feature_name}\")\n",
    "\n",
    "    def parse_all_features(self, get_feature_resp:dict)->dict:\n",
    "\n",
    "        features = get_feature_resp['featureTypes']\n",
    "\n",
    "        parsed = OrderedDict()\n",
    "        for feat in features:\n",
    "            parsed_feat = self.parse_feature_schema(feat)\n",
    "            parsed.update(parsed_feat)\n",
    "            self.raise_for_no_id(parsed_feat)\n",
    "        return parsed\n",
    "\n",
    "    def __call__(self, get_feature_resp:dict)->dict:\n",
    "\n",
    "        return self.parse_all_features(get_feature_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2694f59f-6edd-42e5-8c0f-ddadf07053f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoSampaWfs(BaseClient):\n",
    "\n",
    "    def __init__(self, domain:str, set_schemas:bool=True, verbose:bool=True, auto_paginate:bool=True):\n",
    "\n",
    "        self.get = BaseClient(domain=domain, verbose=verbose)\n",
    "        self.parse_features_schemas = FeatureMdataParser()\n",
    "\n",
    "        self.schemas = self.get_feature_schemas() if set_schemas else None\n",
    "        self.paginate = Paginator(self.get, self.schemas)\n",
    "\n",
    "        self.auto_paginate = auto_paginate\n",
    "    \n",
    "    def __list_feature_types_raw(self):\n",
    "\n",
    "        return self.get('DescribeFeatureType')\n",
    "\n",
    "    def get_feature_schemas(self):\n",
    "\n",
    "        resp  = self.__list_feature_types_raw()\n",
    "        return self.parse_features_schemas(resp)\n",
    "\n",
    "    def __solve_properties(self, query_params, properties:list=None):\n",
    "\n",
    "         if properties:\n",
    "            names = ','.join(properties)\n",
    "            query_params['propertyName']=names\n",
    "\n",
    "    def __check_feature_exists(self, feature_name:str)->None:\n",
    "\n",
    "        if self.schemas and feature_name not in self.schemas:\n",
    "            raise ValueError(f\"Feature name {feature_name} doesn't exits\")\n",
    "\n",
    "    def get_feature(self, feature_name:str, properties:list=None, filter:CQLFilter=None, paginate:bool=None,\n",
    "                    index_col:str=None, **query_params):\n",
    "\n",
    "        self.__check_feature_exists(feature_name)        \n",
    "        self.__solve_properties(query_params, properties)\n",
    "       \n",
    "        if filter is not None:\n",
    "            query_params['cql_filter'] = filter()\n",
    "\n",
    "        resp = self.get('GetFeature', typeName=feature_name, **query_params)\n",
    "\n",
    "        if paginate or (paginate is None and self.auto_paginate):\n",
    "            return self.paginate(feature_name, resp, index_col, **query_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff212b58-dc86-4436-a6f4-7ea5b49844e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b120f01-e418-49ff-9efd-589e1116c941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\General Projects\\Git\\GitHub\\sepep-pmsp\\saade_governancadados\n"
     ]
    }
   ],
   "source": [
    "#ROOT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(''))\n",
    "print (ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98509da9-5334-4eed-8c6d-7afaa0781dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingEnvironmentVariable(RuntimeError):\n",
    "    pass\n",
    "\n",
    "def get_dotenv_path(root: str = ROOT_DIR, example: bool = False) -> str:\n",
    "    \"\"\"Returns .env file path\"\"\"\n",
    "\n",
    "    path = os.path.join(root, \".env\")\n",
    "\n",
    "    if example:\n",
    "        path += \".example\"\n",
    "\n",
    "    return path\n",
    "\n",
    "\n",
    "def dotenv_exits(dotenv_path: str = None, root: str = ROOT_DIR):\n",
    "    \"\"\"Check if .env file path exists\"\"\"\n",
    "\n",
    "    dotenv_path = dotenv_path or get_dotenv_path(root)\n",
    "\n",
    "    return os.path.exists(dotenv_path)\n",
    "\n",
    "\n",
    "def solve_dot_env(root: str = ROOT_DIR) -> str:\n",
    "    \"\"\"Copies .env.example as .env if .env doesnt exists\"\"\"\n",
    "\n",
    "    dotenv_path = get_dotenv_path(root)\n",
    "\n",
    "    if not dotenv_exits(dotenv_path):\n",
    "        warnings.warn(\".env file not found: copying .env.example\")\n",
    "        env_example = get_dotenv_path(root, example=True)\n",
    "        shutil.copy(env_example, dotenv_path)\n",
    "\n",
    "    return dotenv_path\n",
    "\n",
    "\n",
    "def load_env(root: str = ROOT_DIR) -> None:\n",
    "    \"\"\"Loads .env. If .env doesn't exists, will save .env.example\n",
    "    as .env and will load it's variables\"\"\"\n",
    "\n",
    "    env_path = solve_dot_env(root)\n",
    "    load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "\n",
    "def load_var(varname: str, root: str = ROOT_DIR) -> str:\n",
    "    load_env(root)\n",
    "\n",
    "    try:\n",
    "        return os.environ[varname]\n",
    "    except KeyError:\n",
    "        raise MissingEnvironmentVariable(f\"Environment var {varname} not defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bf8e65f-39a5-4f37-a09f-f61ab9a029ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEOSAMPA_WFS_DOMAIN = load_var('GEOSAMPA_WFS_DOMAIN')\n",
    "\n",
    "def get_client(domain=GEOSAMPA_WFS_DOMAIN):\n",
    "    print (GEOSAMPA_WFS_DOMAIN)\n",
    "\n",
    "    return GeoSampaWfs(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "905b0ea1-5deb-4bf9-9583-08228a805e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://wfs.geosampa.prefeitura.sp.gov.br/geoserver/ows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\2719722458.py:51: UserWarning: Could not identify id col for feature geohabisp_vw_wfs_cortico_geosampa\n",
      "  warnings.warn(f\"Could not identify id col for feature {feature_name}\")\n",
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\2719722458.py:51: UserWarning: Could not identify id col for feature geohabisp_vw_wfs_favela_geosampa\n",
      "  warnings.warn(f\"Could not identify id col for feature {feature_name}\")\n",
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\2719722458.py:51: UserWarning: Could not identify id col for feature geohabisp_vw_wfs_loteamento_geosampa\n",
      "  warnings.warn(f\"Could not identify id col for feature {feature_name}\")\n",
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\2719722458.py:51: UserWarning: Could not identify id col for feature geohabisp_vw_wfs_nucleo_geosampa\n",
      "  warnings.warn(f\"Could not identify id col for feature {feature_name}\")\n"
     ]
    }
   ],
   "source": [
    "geosampa = get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7683c98e-e965-4625-b9e5-4914be74e4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\2719722458.py:51: UserWarning: Could not identify id col for feature geohabisp_vw_wfs_cortico_geosampa\n",
      "  warnings.warn(f\"Could not identify id col for feature {feature_name}\")\n",
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\2719722458.py:51: UserWarning: Could not identify id col for feature geohabisp_vw_wfs_favela_geosampa\n",
      "  warnings.warn(f\"Could not identify id col for feature {feature_name}\")\n",
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\2719722458.py:51: UserWarning: Could not identify id col for feature geohabisp_vw_wfs_loteamento_geosampa\n",
      "  warnings.warn(f\"Could not identify id col for feature {feature_name}\")\n",
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\2719722458.py:51: UserWarning: Could not identify id col for feature geohabisp_vw_wfs_nucleo_geosampa\n",
      "  warnings.warn(f\"Could not identify id col for feature {feature_name}\")\n"
     ]
    }
   ],
   "source": [
    "schemas = geosampa.get_feature_schemas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ce4bacf-6eb4-44bb-9495-fe1e5c61ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_exemplos = []\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Zoneamento Geral': { 'camada' : 'pde2014_v_zu_zr_01a_map', 'prefixo_campo': 'geom_macrozoneamento_zu_zr_01a' } })\n",
    "cat.append({ 'Macrozonas': { 'camada' : 'pde2014_v_mcrz_01_map' , 'prefixo_campo': 'geom_macrozoneamento_mcrz_01' } } )\n",
    "cat.append({ 'Macroáreas': { 'camada' : 'pde2014_v_mcrar_02_map' , 'prefixo_campo': 'geom_macrozoneamento_mcrar_02' } })\n",
    "cat.append({ 'Setores': { 'camada' : 'pde2014_v_maem_02a_map' , 'prefixo_campo': 'geom_macrozoneamento_maem_02a' } })\n",
    "cat.append({ 'Eixos Existentes': { 'camada' : 'pde2014_v_eetr_03_map' , 'prefixo_campo': 'geom_macrozoneamento_eetr_03' } })\n",
    "cat.append({ 'Eixos Previstos': { 'camada' : 'pde2014_v_eixo_prv_03a_map' , 'prefixo_campo': 'geom_macrozoneamento_eixo_prv_03a' } })\n",
    "cat.append({ 'Eixos Previstos - Ativados por Decreto': { 'camada' : 'eixo_ativado_decreto' , 'prefixo_campo': 'geom_macrozoneamento_eixo_ativado_decreto' } })\n",
    "\n",
    "dict_exemplos.append({\n",
    "        'identificador': 'geom_macrozoneamento'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_macrozoneamento'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'ZEIS': { 'camada' : 'pde2014_v_zeis_04_map', 'prefixo_campo': 'geom_zeis-pde_4' } })\n",
    "cat.append({ 'ZEIS': { 'camada' : 'pde2014_v_zeis_04a_map' , 'prefixo_campo': 'geom_zeis-pde_4a' } } )\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_zeis-pde'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_zeis-pde'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Zoneamento': { 'camada' : 'zoneamento_2016_map1', 'prefixo_campo': 'geom_zoneamento_perimetro' } })\n",
    "cat.append({ 'Zoneamento - Qualificação Ambiental': { 'camada' : None , 'prefixo_campo': 'geom_zoneamento_quali_amb' } } )\n",
    "cat.append({ 'Zoneamento - Incentivos': { 'camada' : None , 'prefixo_campo': 'geom_zoneamento_incentivo_edif_garag' } } )\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_zoneamento'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_zoneamento'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Operação Urbana': { 'camada' : 'operacao_urbana', 'prefixo_campo': 'geom_operacao_urbana' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_operacao_urbana'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_operacao_urbana'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Área de Intervenção Urbana': { 'camada' : 'perimetro_aiu', 'prefixo_campo': 'geom_aiu_perimetro' } })\n",
    "cat.append({ 'Área de Intervenção Urbana - Adesão': { 'camada' : 'aiu_vl_perimetro_adesao', 'prefixo_campo': 'geom_aiu_vl_perimetro_adesao' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_aiu'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_aiu'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Leis Esparsas - Perimetro Geral': { 'camada' : 'requalifica_centro_perimetro_geral', 'prefixo_campo': 'geom_leis_esparsas_requalifica_centro_perimetro_geral' } })\n",
    "cat.append({ 'Leis Esparsas - Perimetro Especial': { 'camada' : 'requalifica_centro_perimetro_especial', 'prefixo_campo': 'geom_leis_esparsas_requalifica_centro_perimetro_especial' } })\n",
    "cat.append({ 'Leis Esparsas - Mirante Santana': { 'camada' : 'restricao_mirante_santana', 'prefixo_campo': 'geom_leis_esparsas_restricao_mirante_santana' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_leis_esparsas'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_leis_esparsas'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Sub Prefeituras': { 'camada' : 'subprefeitura', 'prefixo_campo': 'geom_subprefeitura' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_subprefeitura'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_subprefeitura'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Distritos': { 'camada' : 'distrito_municipal', 'prefixo_campo': 'geom_distrito' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_distrito'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_distrito'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Melhoramento Viário': { 'camada' : 'geoconvias_lei_melhoramento_vigente', 'prefixo_campo': 'geom_distrito' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_melhoramento_viario'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_melhoramento_viario'        \n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Decretos de Declaração de Interesse Social ou de Utilidade Pública': { 'camada' : 'decreto_utilidade_publica_interesse_social', 'prefixo_campo': 'geom_dis_dup' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_dis_dup'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_dis_dup'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Faixas de Domínio - Dutovias': { 'camada' : 'transpetro_duto', 'prefixo_campo': 'geom_faixas_dominio_duto_oleo_gas' } })\n",
    "cat.append({ 'Faixas de Domínio - Ferrovias - Linha': { 'camada' : 'linha_trem', 'prefixo_campo': 'geom_faixas_dominio_trem_linha' } })\n",
    "cat.append({ 'Faixas de Domínio - Ferrovias': { 'camada' : 'ferrovia_mdc', 'prefixo_campo': 'geom_faixas_dominio_trem_ferrovia' } })\n",
    "cat.append({ 'Faixas de Domínio - Ferrovias - Metrô': { 'camada' : 'linha_metro', 'prefixo_campo': 'geom_faixas_dominio_linha_metro' } })\n",
    "cat.append({ 'Faixas de Domínio - Estradas e Rodovias': { 'camada' : None, 'prefixo_campo': 'geom_faixas_dominio_estrada_rodovia' } })\n",
    "cat.append({ 'Faixas de Domínio - Linhas de Transmissão': { 'camada' : None, 'prefixo_campo': 'geom_faixas_dominio_linha_transmissao' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_faixas_dominio'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_faixas_dominio'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Terra Indígena': { 'camada' : 'GEOSAMPA_terra_indigena', 'prefixo_campo': 'geom_terra_indigena' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_terra_indigena'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_terra_indigena'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Áreas Públicas': { 'camada' : 'calcada', 'prefixo_campo': 'geom_areas_publicas' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_areas_publicas'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_areas_publicas'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Faixa Não Edificável - Dutovias': { 'camada' : 'transpetro_duto', 'prefixo_campo': 'geom_faixas_nao_edificaveis_duto_oleo_gas' } })\n",
    "cat.append({ 'Faixa Não Edificável - Ferrovias - Linha': { 'camada' : 'linha_trem', 'prefixo_campo': 'geom_faixas_nao_edificaveis_trem_linha' } })\n",
    "cat.append({ 'Faixa Não Edificável - Ferrovias': { 'camada' : 'ferrovia_mdc', 'prefixo_campo': 'geom_faixas_nao_edificaveis_trem_ferrovia' } })\n",
    "cat.append({ 'Faixa Não Edificável - Ferrovias - Metrô': { 'camada' : 'linha_metro', 'prefixo_campo': 'geom_faixas_nao_edificaveis_linha_metro' } })\n",
    "cat.append({ 'Faixa Não Edificável - Estradas e Rodovias': { 'camada' : None, 'prefixo_campo': 'geom_faixas_nao_edificaveis_estrada_rodovia' } })\n",
    "cat.append({ 'Faixa Não Edificável - Equipamentos Públicos': { 'camada' : None, 'prefixo_campo': 'geom_faixas_nao_edificaveis_equip_publico' } })\n",
    "cat.append({ 'Faixa Não Edificável - Equipamentos Públicos Arruamento': { 'camada' : 'decreto_utilidade_publica_interesse_social', 'prefixo_campo': 'geom_faixas_nao_edificaveis_equip_publico_arr' } })\n",
    "cat.append({ 'Faixa Não Edificável - Equipamentos Públicos Área Urbana Regularizada': { 'camada' : 'decreto_utilidade_publica_interesse_social', 'prefixo_campo': 'geom_faixas_nao_edificaveis_equip_publico_au' } })\n",
    "cat.append({ 'Faixa Não Edificável - Melhoramentos Públicos': { 'camada' : None, 'prefixo_campo': 'geom_faixas_nao_edificaveis_melhora_publico' } })\n",
    "cat.append({ 'Faixa Não Edificável - Águas Correntes ou Dormentes - Drenagem - Estado Natural': { 'camada' : 'drenagem', 'prefixo_campo': 'geom_faixas_nao_edificaveis_agua_corr_dormente_drena_natural' } })\n",
    "cat.append({ 'Faixa Não Edificável - Águas Correntes ou Dormentes - Drenagem - Lago/Reservatório': { 'camada' : 'drenagem', 'prefixo_campo': 'geom_faixas_nao_edificaveis_agua_corr_dormente_drena_lago_res' } })\n",
    "cat.append({ 'Faixa Não Edificável - Águas Correntes ou Dormentes - Massa D''água': { 'camada' : 'massa_d_agua', 'prefixo_campo': 'geom_faixas_nao_edificaveis_agua_corr_dormente_massa_dagua' } })\n",
    "cat.append({ 'Faixa Não Edificável - Águas Correntes ou Dormentes - Represa': { 'camada' : 'represa_nivel_maximo', 'prefixo_campo': 'geom_faixas_nao_edificaveis_agua_corr_dormente_represa' } })\n",
    "cat.append({ 'Faixa Não Edificável - Galerias e Canalizações - Infraestrutura': { 'camada' : 'geoconvias_faixa_nao_edificavel', 'prefixo_campo': 'geom_faixas_nao_edificaveis_galeria_canal_infraest' } })\n",
    "cat.append({ 'Faixa Não Edificável - Galerias e Canalizações - Drenagem - Céu aberto': { 'camada' : 'drenagem', 'prefixo_campo': 'geom_faixas_nao_edificaveis_galeria_canal_drena_ceu_aberto' } })\n",
    "cat.append({ 'Faixa Não Edificável - Galerias e Canalizações - Drenagem - Subterrânea': { 'camada' : 'drenagem', 'prefixo_campo': 'geom_faixas_nao_edificaveis_galeria_canal_drena_subterra' } })\n",
    "cat.append({ 'Faixa Não Edificável - Galerias e Canalizações - Massa D''água': { 'camada' : 'massa_d_agua', 'prefixo_campo': 'geom_faixas_nao_edificaveis_galeria_canal_massa_dagua' } })\n",
    "cat.append({ 'Faixa Não Edificável - Linhas de Transmissão': { 'camada' : None, 'prefixo_campo': 'geom_faixas_nao_edificaveis_linha_transmissao' } })\n",
    "\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_faixas_nao_edificaveis'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_faixas_nao_edificaveis'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Cartório de Registro de Imóveis': { 'camada' : 'cartorio_registro_imovel', 'prefixo_campo': 'geom_cartorio_registro_imoveis' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_cartorio_registro_imoveis'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_cartorio_registro_imoveis'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Espaço Aéreo - Heliponto': { 'camada' : 'GEOSAMPA_heliponto', 'prefixo_campo': 'geom_espaco_aereo_heliponto' } })\n",
    "cat.append({ 'Espaço Aéreo - Rota de Aviões e Helicópteros': { 'camada' : None, 'prefixo_campo': 'geom_espaco_aereo_rota_avioes_helicopteros' } })\n",
    "cat.append({ 'Espaço Aéreo - Plano': { 'camada' : None, 'prefixo_campo': 'geom_espaco_aereo_plano' } })\n",
    "cat.append({ 'Espaço Aéreo - Auxílio à Navegação - Ponto': { 'camada' : None, 'prefixo_campo': 'geom_espaco_aereo_auxilio_navegacao_ponto' } })\n",
    "cat.append({ 'Espaço Aéreo - Auxílio à Navegação - Linha': { 'camada' : None, 'prefixo_campo': 'geom_espaco_aereo_auxilio_navegacao_linha' } })\n",
    "cat.append({ 'Espaço Aéreo - Auxílio à Navegação': { 'camada' : None, 'prefixo_campo': 'geom_espaco_aereo_auxilio_navegacao' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_espaco_aereo'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_espaco_aereo'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Mini Anel Viário': { 'camada' : 'restricao_circulacao_veiculo_mian', 'prefixo_campo': 'geo_minianel_viario' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geo_minianel_viario'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geo_minianel_viario'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Logradouro': { 'camada' : None, 'prefixo_campo': 'geom_logradouro_identificacao_logradouro' } })\n",
    "cat.append({ 'Logradouro SF': { 'camada' : None, 'prefixo_campo': 'geom_logradouro_identificacao_logradouro_sf' } })\n",
    "cat.append({ 'Classificação urbanística - Quadro 9.N1': { 'camada' : 'classificacao_viaria_quadro_9', 'prefixo_campo': 'geom_logradouro_class_viaria_q9n1' } })\n",
    "cat.append({ 'Classificação urbanística - Quadro 9.N2': { 'camada' : 'classificacao_viaria_quadro_9', 'prefixo_campo': 'geom_logradouro_class_viaria_q9n2' } })\n",
    "cat.append({ 'Classificação urbanística - Quadro 9.N3': { 'camada' : 'classificacao_viaria_quadro_9', 'prefixo_campo': 'geom_logradouro_class_viaria_q9n3' } })\n",
    "cat.append({ 'Classificação urbanística - Coletora CET': { 'camada' : 'classificacao_viaria_cet', 'prefixo_campo': 'geom_logradouro_class_viaria_cet_coletora' } })\n",
    "cat.append({ 'Classificação urbanística - Local CET': { 'camada' : 'classificacao_viaria_cet', 'prefixo_campo': 'geom_logradouro_class_viaria_cet_local' } })\n",
    "cat.append({ 'Classificação urbanística - Vias Pedestre CET': { 'camada' : 'classificacao_viaria_cet', 'prefixo_campo': 'geom_logradouro_class_viaria_cet_via_pedestre' } })\n",
    "cat.append({ 'Estradas e Rodovias': { 'camada' : None, 'prefixo_campo': 'geom_logradouro_estrada_rodovia' } })\n",
    "cat.append({ 'Vias relacionadas a zonas': { 'camada' : None, 'prefixo_campo': 'geom_logradouro_via_relac_zonas' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_logradouro'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_logradouro'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Tipo de Logradouro': { 'camada' : None, 'prefixo_campo': 'geom_tipo_logradouro' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_tipo_logradouro' #CADLOG\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_tipo_logradouro'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Face da Quadra': { 'camada' : None, 'prefixo_campo': 'geom_face_quadra' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_face_quadra'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_face_quadra'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Rua Sem Saída': { 'camada' : None, 'prefixo_campo': 'geom_rua_sem_saida' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_rua_sem_saida'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_rua_sem_saida'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Vila': { 'camada' : None, 'prefixo_campo': 'geom_vila' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_vila'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_vila'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Entorno de Vila': { 'camada' : None, 'prefixo_campo': 'geom_entorno_vila' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_entorno_vila'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_entorno_vila'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Curvas de Nível - Curva Mestra': { 'camada' : 'curva_mestra', 'prefixo_campo': 'geom_curvas_nivel_mestra' } })\n",
    "cat.append({ 'Curvas de Nível - Curva Intermediária': { 'camada' : 'curva_intermediaria', 'prefixo_campo': 'geom_curvas_nivel_intermediaria' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_curvas_nivel'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_curvas_nivel'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'CEDI': { 'camada' : None, 'prefixo_campo': 'geom_cedi' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_cedi' #CEDI\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_cedi'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "\"\"\"\n",
    "cat = []\n",
    "cat.append({ 'Lote Fiscal': { 'camada' : 'lote_cidadao', 'prefixo_campo': 'geom_lote_fiscal' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_lote_fiscal'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_lote_fiscal'\n",
    "        ,\n",
    "    })\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'TPCL': { 'camada' : None, 'prefixo_campo': 'geom_tpcl' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_tpcl' #TPCL\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name' : 'geom_tpcl'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Billings - APPB': { 'camada' : 'manancial_billings', 'prefixo_campo': 'geom_app_billings_appb' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_app'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_app'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Unidade de Conservação - APA': { 'camada' : None, 'prefixo_campo': 'geom_uc_apa' } })\n",
    "cat.append({ 'Unidade de Conservação - PE': { 'camada' : None, 'prefixo_campo': 'geom_uc_pe' } })\n",
    "cat.append({ 'Unidade de Conservação - PNM': { 'camada' : None, 'prefixo_campo': 'geom_uc_pnm' } })\n",
    "cat.append({ 'Unidade de Conservação - RPPN': { 'camada' : None, 'prefixo_campo': 'geom_uc_rppn' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_uc'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_uc'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Área de Proteção aos Mananciais': { 'camada' : None, 'prefixo_campo': 'geom_apm' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_apm'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_apm'\n",
    "        ,\n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Área de Proteção de Recuperação de Mananciais - Billings': { 'camada' : 'manancial_billings', 'prefixo_campo': 'geom_aprm_billings' } })\n",
    "cat.append({ 'Área de Proteção de Recuperação de Mananciais - Guarapiranga': { 'camada' : 'manancial_guarapiranga', 'prefixo_campo': 'geom_aprm_guarapiranga' } })\n",
    "cat.append({ 'Área de Proteção de Recuperação de Mananciais - Ato Juquery': { 'camada' : 'manancial_juquery', 'prefixo_campo': 'geom_aprm_juquery' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_aprm'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_aprm'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Reserva Legal': { 'camada' : None, 'prefixo_campo': 'geom_reserva_legal' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_reserva_legal'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_reserva_legal'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Vegetação Árborea - Maçicos e Bosques': { 'camada' : 'cobertura_vegetal', 'prefixo_campo': 'geom_vegetacao_arborea_macicos_bosques' } })\n",
    "cat.append({ 'Vegetação Árborea - Arbustiva e Arborescente': { 'camada' : 'cobertura_vegetal', 'prefixo_campo': 'geom_vegetacao_arborea_arbustiva_arborescente' } })\n",
    "cat.append({ 'Vegetação Árborea - Viária/Árvores': { 'camada' : 'arvore', 'prefixo_campo': 'geom_vegetacao_arborea_viaria_arvores' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_vegetacao_arborea'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_vegetacao_arborea'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Bioma Mata Atlântica': { 'camada' : 'remanescente_pmma', 'prefixo_campo': 'geom_biomas_protegidos_mata_atlantica' } })\n",
    "cat.append({ 'Bioma Cerrado': { 'camada' : None, 'prefixo_campo': 'geom_biomas_protegidos_cerrado' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_biomas_protegidos'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_biomas_protegidos'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Termo de Compromisso Ambiental': { 'camada' : 'termo_compromisso_ambiental_svma', 'prefixo_campo': 'geom_tca' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_tca'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_tca'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'TAC Ambiental': { 'camada' : None, 'prefixo_campo': 'geom_tac_ambiental' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_tac_ambiental'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_tac_ambiental'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Vegetação em APP suprimida irregularmente': { 'camada' : None, 'prefixo_campo': 'geom_supressao_irregular_vegetacao_arborea_app_irr' } })\n",
    "cat.append({ 'Vegetação em APP suprimida irregularmente recomposta': { 'camada' : None, 'prefixo_campo': 'geom_supressao_irregular_vegetacao_arborea_app_irr_rec' } })\n",
    "cat.append({ 'Vegetação significativa suprimida irregularmente': { 'camada' : None, 'prefixo_campo': 'geom_supressao_irregular_vegetacao_arborea_irr' } })\n",
    "cat.append({ 'Vegetação significativa suprimida irregularmente recomposta': { 'camada' : None, 'prefixo_campo': 'geom_supressao_irregular_vegetacao_arborea_irr_rec' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_supressao_irregular_vegetacao_arborea'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_supressao_irregular_vegetacao_arborea'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Área Contaminada': { 'camada' : 'area_contaminada_reabilitada_svma', 'prefixo_campo': 'geom_area_contaminada' } })\n",
    "cat.append({ 'Área Contaminada e Reabilitada': { 'camada' : 'area_contaminada_reabilitada_svma', 'prefixo_campo': 'geom_area_contaminada_reabilitada' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_area_contaminada'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_area_contaminada'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Servidão Ambiental': { 'camada' : None, 'prefixo_campo': 'geom_servidao_ambiental' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_servidao_ambiental'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_servidao_ambiental'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Serviços Ambientais': { 'camada' : None, 'prefixo_campo': 'geom_servicos_ambientais' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_servicos_ambientais'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_servicos_ambientais'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Espaço Áereo - Ruído': { 'camada' : None, 'prefixo_campo': 'geom_espaço_aereo_ruido' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_espaço_aereo_ruido'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_espaço_aereo_ruido'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Risco Geológico': { 'camada' : '', 'prefixo_campo': 'geom_espaço_aereo_ruido' } })\n",
    "cat.append({ 'Risco Hidrológico': { 'camada' : '', 'prefixo_campo': 'geom_risco_geologico_hidrologico' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_risco_geologico'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_risco_geologico'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Restrição Geotécnica': { 'camada' : 'restricao_geotecnica', 'prefixo_campo': 'geom_restricao_geotecnica' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_restricao_geotecnica'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_restricao_geotecnica'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Bem Tombado e/ou em Processo de Tombamento': { 'camada' : 'patrimonio_cultural_bem_tombado', 'prefixo_campo': 'geom_tombado' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_tombado'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_tombado'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Área Envoltória CONDEPHAAT': { 'camada' : 'patrimonio_cultural_area_envoltoria_CONDEPHAAT', 'prefixo_campo': 'geom_area_envoltoria_condephaat' } })\n",
    "cat.append({ 'Área Envoltória CONPRESP': { 'camada' : 'patrimonio_cultural_area_envoltoria_CONPRESP', 'prefixo_campo': 'geom_area_envoltoria_condephaat' } })\n",
    "cat.append({ 'Área Envoltória IPHAN': { 'camada' : 'patrimonio_cultural_area_envoltoria_IPHAN', 'prefixo_campo': 'geom_area_envoltoria_iphan' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_area_envoltoria'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_area_envoltoria'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Bairro Ambiental': { 'camada' : 'patrimonio_cultural_bairro_ambiental', 'prefixo_campo': 'geom_area_tombada_bairro_ambiental' } })\n",
    "cat.append({ 'Lugar de Interesse Paisagístico Ambiental': { 'camada' : 'patrimonio_cultural_lugar_paisagistico_ambiental', 'prefixo_campo': 'geom_area_tombada_lugar_paisagistico_ambiental' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_area_tombada'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_area_tombada'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Preservações Culturais - Sítio Arqueológico': { 'camada' : 'patrimonio_cultural_sitio_arqueologico', 'prefixo_campo': 'geom_preservacoes_culturais_sitio_arqueologico' } })\n",
    "cat.append({ 'Preservações Culturais - Ocorrência Arqueológica': { 'camada' : 'patrimonio_cultural_ocorrencia_arqueologica', 'prefixo_campo': 'geom_preservacoes_culturais_occ_arqueologica' } })\n",
    "cat.append({ 'Preservações Culturais - Bem de Interesse Arqueológico': { 'camada' : 'patrimonio_cultural_bem_arqueologico', 'prefixo_campo': 'geom_preservacoes_culturais_beminter_arqueologico' } })\n",
    "cat.append({ 'Preservações Culturais - Área de Interesse Arqueológico': { 'camada' : 'patrimonio_cultural_area_arqueologica', 'prefixo_campo': 'geom_preservacoes_culturais_arinter_arqueologico' } })\n",
    "cat.append({ 'Preservações Culturais - Acervo Tombado': { 'camada' : 'patrimonio_cultural_acervo_tombado', 'prefixo_campo': 'geom_preservacoes_culturais_ac_tombado' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_outras_preservacoes_culturais'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_outras_preservacoes_culturais'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'TAC Cultural': { 'camada' : None, 'prefixo_campo': 'geom_tac_cultural' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_tac_cultural'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_tac_cultural'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'TAC Urbanistico': { 'camada' : None, 'prefixo_campo': 'geom_tac_urbanistico' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_tac_urbanistico'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_tac_urbanistico'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Registro Profissional': { 'camada' : None, 'prefixo_campo': 'registro_profissional' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'registro_profissional'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'registro_profissional'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Responsabilidade Técnica': { 'camada' : None, 'prefixo_campo': 'doc_responsabilidade_tecnica' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'doc_responsabilidade_tecnica'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'doc_responsabilidade_tecnica'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Autorização para bancas de jornal': { 'camada' : None, 'prefixo_campo': 'geom_intervencoes_passeio_bancas' } })\n",
    "cat.append({ 'Autorização para uso do passeio': { 'camada' : None, 'prefixo_campo': 'geom_intervencoes_passeio_uso' } })\n",
    "cat.append({ 'Obras no passeio': { 'camada' : None, 'prefixo_campo': 'geom_intervencoes_passeio_obras' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_intervencoes_passeio'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_intervencoes_passeio'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'Embargos de obra': { 'camada' : None, 'prefixo_campo': 'geom_embargos' } })\n",
    "cat.append({ 'Interdições de imóvel': { 'camada' : None, 'prefixo_campo': 'geom_interdicoes' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'geom_embargos_interdicoes'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'geom_embargos_interdicoes'\n",
    "        , \n",
    "    })\n",
    "\n",
    "cat = []\n",
    "cat.append({ 'CAB': { 'camada' : None, 'prefixo_campo': 'CAB' } })\n",
    "dict_exemplos.append(\n",
    "    {\n",
    "        'identificador': 'CAB'\n",
    "        , 'categorias': tuple(cat)\n",
    "        , 'sheet_name': 'CAB'\n",
    "        , \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2466a8c2-ce2f-4812-b3f8-8500ca8f626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c59e6d12-183f-48d2-96cf-cde801c9f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e78b2a4f-3983-4b22-9e57-be0ebc74a20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def escreve_excel(dfs, arquivo):\n",
    "    with pd.ExcelWriter(arquivo) as writer:  \n",
    "        for k, v in dfs.items():\n",
    "            (v).to_excel(writer, sheet_name = k, index=False)\n",
    "    # df.to_excel(arquivo, sheet_name=planilha, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42b241df-2f41-4c3f-882e-55609d2000c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trata_coluna(col, id_col, index, camada, identificador, categoria, prefixo_campo, totalFeatures, numberMatched, numberReturned, dth_extracao):\n",
    "    ds= []\n",
    "    dfCol = pd.DataFrame(\n",
    "        columns = ['Id', 'identificador', 'categoria', 'camada', 'prefixo_campo','totalFeatures','numberMatched','numberReturned','dth_extracao', 'atributo', 'flg_chave', 'flg_nullable', 'datatype', 'qtd_distinct_values']    \n",
    "    )\n",
    "    \n",
    "    dfColDePara = pd.DataFrame(\n",
    "        columns = ['Id', 'identificador', 'categoria', 'camada', 'prefixo_campo','totalFeatures','numberMatched','numberReturned','dth_extracao', 'atributo', 'flg_chave', 'flg_nullable', 'datatype', 'qtd_distinct_values', 'valor_de', 'valor_para']    \n",
    "    )\n",
    "    key = 'Sim' if col == id_col else 'Não'\n",
    "    prop_dict = (schemas[camada])[col]\n",
    "    nullable = 'Sim' if prop_dict['nullable'] else 'Não'\n",
    "    datatype =  prop_dict['dtype']\n",
    "\n",
    "    if key == 'Sim':\n",
    "        arr = np.array([index, '-'])\n",
    "        df = pd.DataFrame([arr], columns=['Id', 'valor_de'])            \n",
    "        qtd_distinct_values = totalFeatures\n",
    "    elif col == 'ge_multipoligono' or col == 'ge_poligono' or col == 'ge_linha' or col == 'ge_ponto':\n",
    "        arr = np.array([index, '-'])\n",
    "        df = pd.DataFrame([arr], columns=['Id', 'valor_de'])            \n",
    "        qtd_distinct_values = totalFeatures\n",
    "    else:\n",
    "        distinct_arr = []\n",
    "        # k = 0\n",
    "        for v in features:\n",
    "            \"\"\"\n",
    "            k += 1\n",
    "            if k % 50000 == 0:\n",
    "                print(f\"{k} of {totalFeatures}: {(k / totalFeatures):%}\")                \n",
    "            \n",
    "            if col == 'ge_multipoligono' or col == 'ge_poligono' or col == 'ge_linha' or col == 'ge_ponto':\n",
    "                try:\n",
    "                    distinct_arr.append([index, item] for item in ((v['geometry'])['coordinates']))\n",
    "                except:\n",
    "                    distinct_arr.append([index, None])\n",
    "            else:\n",
    "                distinct_arr.append([index, (v['properties'])[col]])\n",
    "            \"\"\"\n",
    "\n",
    "            distinct_arr.append([index, (v['properties'])[col]])\n",
    "        try:\n",
    "            df = pd.DataFrame(distinct_arr, columns=['Id', 'valor_de']) \n",
    "            df.drop_duplicates(keep='first', inplace=True)  #dropa os duplicados sem copiar para outro objeto mantendo a primeira observação do mesmo\n",
    "            qtd_distinct_values = df.shape[0]\n",
    "        except Exception as error:\n",
    "            messages.append(f\"### Erro ao deduplicar dados {camada} - {col}: {type(error).__name__} – {error} ! ### </ br>\")\n",
    "            arr = np.array([index, '-'])\n",
    "            df = pd.DataFrame([arr], columns=['Id', 'valor_de'])\n",
    "            qtd_distinct_values = totalFeatures\n",
    "        \n",
    "    ds.append([index, identificador, categoria, camada, prefixo_campo, totalFeatures, numberMatched, numberReturned, dth_extracao, col, key, nullable, datatype, qtd_distinct_values])\n",
    "    dfCol = pd.DataFrame(ds, columns=['Id', 'identificador', 'categoria', 'camada', 'prefixo_campo','totalFeatures','numberMatched','numberReturned','dth_extracao', 'atributo', 'flg_chave', 'flg_nullable', 'datatype', 'qtd_distinct_values'])\n",
    "    dfColDePara = pd.DataFrame(ds, columns=['Id', 'identificador', 'categoria', 'camada', 'prefixo_campo','totalFeatures','numberMatched','numberReturned','dth_extracao', 'atributo', 'flg_chave', 'flg_nullable', 'datatype', 'qtd_distinct_values'])\n",
    "    \n",
    "    pct_distinct_values = qtd_distinct_values / totalFeatures\n",
    "    var_discreta = key == 'Sim' or (pct_distinct_values > 0.94999 and totalFeatures > 500) or col == 'ge_multipoligono' or col == 'ge_poligono' or col == 'ge_linha'\n",
    "    \n",
    "    empty_values = var_discreta == True or qtd_distinct_values == 0 or qtd_distinct_values > 1000 \n",
    "            \n",
    "    if empty_values:\n",
    "        dfColDePara = dfCol.assign(valor_de = \"\", valor_para = \"\")\n",
    "\n",
    "        dfCol.drop([\"Id\"], axis=1, inplace=True)\n",
    "        dfColDePara.drop([\"Id\"], axis=1, inplace=True)\n",
    "    else:            \n",
    "        # dfValues = pd.DataFrame(distinct_values, columns=[\"valor_de\"])\n",
    "        # l = pd.concat([dfValues.assign(Id=row.Id) for _, row in dfColDePara.iterrows()])\n",
    "\n",
    "        #adiciona um sufixo qualquer para a coluna adicional para usar como busca de coluan a ser removida\n",
    "        # remove as colunas do merge adicionais usadas como chave        \n",
    "        dfTmp = pd.merge(dfCol, df, how=\"inner\", on=[\"Id\", \"Id\"], suffixes=('_xykey_x', '_xykey_y'))\n",
    "        dfTmp.drop([i for i in dfTmp.columns if '_xykey_' in i], axis=1, inplace=True)        \n",
    "        dfColDePara = dfTmp.assign(valor_para = \"\")\n",
    "        \n",
    "        dfCol.drop([\"Id\"], axis=1, inplace=True)\n",
    "        dfColDePara.drop([\"Id\"], axis=1, inplace=True)        \n",
    "        \n",
    "    # print(f\"shape {col} ===> dfCol: {dfCol.shape} | dfColDePara: {dfColDePara.shape}\")\n",
    "    return dfCol, dfColDePara        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc561043-3235-494b-9163-346b34055eb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exemplo: geom_macrozoneamento - planilha: geom_macrozoneamento 2024-08-30 18:41:36\n",
      "exemplo: geom_zeis-pde - planilha: geom_zeis-pde 2024-08-30 18:41:43\n",
      "exemplo: geom_zoneamento - planilha: geom_zoneamento 2024-08-30 18:41:44\n",
      "Paginação iniciada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\1456900941.py:22: UserWarning: Paginação iniciada. Serão realizadas 3 requisições para a zoneamento_2016_map1\n",
      "  warnings.warn(f\"Paginação iniciada. Serão realizadas {total_steps} requisições para a {feature_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exemplo: geom_operacao_urbana - planilha: geom_operacao_urbana 2024-08-30 18:42:26\n",
      "exemplo: geom_aiu - planilha: geom_aiu 2024-08-30 18:42:26\n",
      "exemplo: geom_leis_esparsas - planilha: geom_leis_esparsas 2024-08-30 18:42:27\n",
      "exemplo: geom_subprefeitura - planilha: geom_subprefeitura 2024-08-30 18:42:29\n",
      "exemplo: geom_distrito - planilha: geom_distrito 2024-08-30 18:42:30\n",
      "exemplo: geom_melhoramento_viario - planilha: geom_melhoramento_viario 2024-08-30 18:42:31\n",
      "exemplo: geom_dis_dup - planilha: geom_dis_dup 2024-08-30 18:42:33\n",
      "exemplo: geom_faixas_dominio - planilha: geom_faixas_dominio 2024-08-30 18:42:34\n",
      "exemplo: geom_terra_indigena - planilha: geom_terra_indigena 2024-08-30 18:42:35\n",
      "exemplo: geom_areas_publicas - planilha: geom_areas_publicas 2024-08-30 18:42:36\n",
      "Paginação iniciada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\1456900941.py:22: UserWarning: Paginação iniciada. Serão realizadas 17 requisições para a calcada\n",
      "  warnings.warn(f\"Paginação iniciada. Serão realizadas {total_steps} requisições para a {feature_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exemplo: geom_faixas_nao_edificaveis - planilha: geom_faixas_nao_edificaveis 2024-08-30 18:45:23\n",
      "exemplo: geom_cartorio_registro_imoveis - planilha: geom_cartorio_registro_imoveis 2024-08-30 18:46:27\n",
      "exemplo: geom_espaco_aereo - planilha: geom_espaco_aereo 2024-08-30 18:46:27\n",
      "exemplo: geo_minianel_viario - planilha: geo_minianel_viario 2024-08-30 18:46:30\n",
      "exemplo: geom_logradouro - planilha: geom_logradouro 2024-08-30 18:46:30\n",
      "Paginação iniciada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\1456900941.py:22: UserWarning: Paginação iniciada. Serão realizadas 7 requisições para a classificacao_viaria_quadro_9\n",
      "  warnings.warn(f\"Paginação iniciada. Serão realizadas {total_steps} requisições para a {feature_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paginação iniciada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\1456900941.py:22: UserWarning: Paginação iniciada. Serão realizadas 7 requisições para a classificacao_viaria_quadro_9\n",
      "  warnings.warn(f\"Paginação iniciada. Serão realizadas {total_steps} requisições para a {feature_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paginação iniciada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\1456900941.py:22: UserWarning: Paginação iniciada. Serão realizadas 7 requisições para a classificacao_viaria_quadro_9\n",
      "  warnings.warn(f\"Paginação iniciada. Serão realizadas {total_steps} requisições para a {feature_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paginação iniciada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\1456900941.py:22: UserWarning: Paginação iniciada. Serão realizadas 8 requisições para a classificacao_viaria_cet\n",
      "  warnings.warn(f\"Paginação iniciada. Serão realizadas {total_steps} requisições para a {feature_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paginação iniciada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\1456900941.py:22: UserWarning: Paginação iniciada. Serão realizadas 8 requisições para a classificacao_viaria_cet\n",
      "  warnings.warn(f\"Paginação iniciada. Serão realizadas {total_steps} requisições para a {feature_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paginação iniciada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\1456900941.py:22: UserWarning: Paginação iniciada. Serão realizadas 8 requisições para a classificacao_viaria_cet\n",
      "  warnings.warn(f\"Paginação iniciada. Serão realizadas {total_steps} requisições para a {feature_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exemplo: geom_tipo_logradouro - planilha: geom_tipo_logradouro 2024-08-30 18:50:06\n",
      "exemplo: geom_face_quadra - planilha: geom_face_quadra 2024-08-30 18:50:06\n",
      "exemplo: geom_rua_sem_saida - planilha: geom_rua_sem_saida 2024-08-30 18:50:06\n",
      "exemplo: geom_vila - planilha: geom_vila 2024-08-30 18:50:06\n",
      "exemplo: geom_entorno_vila - planilha: geom_entorno_vila 2024-08-30 18:50:06\n",
      "exemplo: geom_curvas_nivel - planilha: geom_curvas_nivel 2024-08-30 18:50:06\n",
      "Paginação iniciada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\1456900941.py:22: UserWarning: Paginação iniciada. Serão realizadas 9 requisições para a curva_mestra\n",
      "  warnings.warn(f\"Paginação iniciada. Serão realizadas {total_steps} requisições para a {feature_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paginação iniciada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\1456900941.py:22: UserWarning: Paginação iniciada. Serão realizadas 24 requisições para a curva_intermediaria\n",
      "  warnings.warn(f\"Paginação iniciada. Serão realizadas {total_steps} requisições para a {feature_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exemplo: geom_cedi - planilha: geom_cedi 2024-08-30 19:00:22\n",
      "exemplo: geom_tpcl - planilha: geom_tpcl 2024-08-30 19:00:22\n",
      "exemplo: geom_app - planilha: geom_app 2024-08-30 19:00:22\n",
      "exemplo: geom_uc - planilha: geom_uc 2024-08-30 19:00:34\n",
      "exemplo: geom_apm - planilha: geom_apm 2024-08-30 19:00:34\n",
      "exemplo: geom_aprm - planilha: geom_aprm 2024-08-30 19:00:34\n",
      "exemplo: geom_reserva_legal - planilha: geom_reserva_legal 2024-08-30 19:00:38\n",
      "exemplo: geom_vegetacao_arborea - planilha: geom_vegetacao_arborea 2024-08-30 19:00:38\n",
      "Paginação iniciada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\1456900941.py:22: UserWarning: Paginação iniciada. Serão realizadas 10 requisições para a cobertura_vegetal\n",
      "  warnings.warn(f\"Paginação iniciada. Serão realizadas {total_steps} requisições para a {feature_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paginação iniciada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\1456900941.py:22: UserWarning: Paginação iniciada. Serão realizadas 10 requisições para a cobertura_vegetal\n",
      "  warnings.warn(f\"Paginação iniciada. Serão realizadas {total_steps} requisições para a {feature_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paginação iniciada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_42424\\1456900941.py:22: UserWarning: Paginação iniciada. Serão realizadas 22 requisições para a arvore\n",
      "  warnings.warn(f\"Paginação iniciada. Serão realizadas {total_steps} requisições para a {feature_name}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exemplo: geom_biomas_protegidos - planilha: geom_biomas_protegidos 2024-08-30 19:10:15\n",
      "exemplo: geom_tca - planilha: geom_tca 2024-08-30 19:10:19\n",
      "exemplo: geom_tac_ambiental - planilha: geom_tac_ambiental 2024-08-30 19:10:21\n",
      "exemplo: geom_supressao_irregular_vegetacao_arborea - planilha: geom_supressao_irregular_vegetacao_arborea 2024-08-30 19:10:21\n",
      "exemplo: geom_area_contaminada - planilha: geom_area_contaminada 2024-08-30 19:10:21\n",
      "exemplo: geom_servidao_ambiental - planilha: geom_servidao_ambiental 2024-08-30 19:10:22\n",
      "exemplo: geom_servicos_ambientais - planilha: geom_servicos_ambientais 2024-08-30 19:10:22\n",
      "exemplo: geom_espaço_aereo_ruido - planilha: geom_espaço_aereo_ruido 2024-08-30 19:10:22\n",
      "exemplo: geom_risco_geologico - planilha: geom_risco_geologico 2024-08-30 19:10:22\n",
      "exemplo: geom_restricao_geotecnica - planilha: geom_restricao_geotecnica 2024-08-30 19:10:22\n",
      "exemplo: geom_tombado - planilha: geom_tombado 2024-08-30 19:10:22\n",
      "exemplo: geom_area_envoltoria - planilha: geom_area_envoltoria 2024-08-30 19:10:26\n",
      "exemplo: geom_area_tombada - planilha: geom_area_tombada 2024-08-30 19:10:27\n",
      "exemplo: geom_outras_preservacoes_culturais - planilha: geom_outras_preservacoes_culturais 2024-08-30 19:10:27\n",
      "exemplo: geom_tac_cultural - planilha: geom_tac_cultural 2024-08-30 19:10:28\n",
      "exemplo: geom_tac_urbanistico - planilha: geom_tac_urbanistico 2024-08-30 19:10:28\n",
      "exemplo: registro_profissional - planilha: registro_profissional 2024-08-30 19:10:28\n",
      "exemplo: doc_responsabilidade_tecnica - planilha: doc_responsabilidade_tecnica 2024-08-30 19:10:28\n",
      "exemplo: geom_intervencoes_passeio - planilha: geom_intervencoes_passeio 2024-08-30 19:10:28\n",
      "exemplo: geom_embargos_interdicoes - planilha: geom_embargos_interdicoes 2024-08-30 19:10:28\n",
      "exemplo: CAB - planilha: CAB 2024-08-30 19:10:28\n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    "dfsDP = {}\n",
    "\n",
    "for ex in dict_exemplos:    \n",
    "    identificador = ex['identificador']\n",
    "    planilha = ex['sheet_name']\n",
    "    print(f\"exemplo: {identificador} - planilha: {planilha} {datetime.datetime.now():%Y-%m-%d %H:%M:%S}\")\n",
    "    ds = []\n",
    "    df = pd.DataFrame(\n",
    "        columns = ['identificador', 'categoria', 'camada', 'prefixo_campo','totalFeatures','numberMatched','numberReturned','dth_extracao', 'atributo', 'flg_chave', 'flg_nullable', 'datatype', 'qtd_distinct_values']    \n",
    "    )\n",
    "    dfDP = pd.DataFrame(\n",
    "        columns = ['identificador', 'categoria', 'camada', 'prefixo_campo','totalFeatures','numberMatched','numberReturned','dth_extracao', 'atributo', 'flg_chave', 'flg_nullable', 'datatype', 'qtd_distinct_values', 'valor_de', 'valor_para']    \n",
    "    )\n",
    "    for item in ex['categorias']: \n",
    "       for categoria in item.keys():\n",
    "           camada = (item[categoria])['camada']\n",
    "           prefixo_campo = (item[categoria])['prefixo_campo']\n",
    "           \n",
    "           features = totalFeatures = numberMatched = numberReturned = ts = dth_extracao = col = None\n",
    "           key = nullable = 'Não'\n",
    "           datatype = distinct_values = None\n",
    "           qtd_distinct_values = 0\n",
    "\n",
    "           if camada:\n",
    "               retorno = geosampa.get_feature(camada)\n",
    "               features = retorno['features']\n",
    "               totalFeatures = retorno['totalFeatures']\n",
    "               numberMatched = retorno['numberMatched']\n",
    "               numberReturned = retorno['numberReturned']\n",
    "               \n",
    "               ts = retorno['timeStamp'] # exemplo: #2024-08-10T02:53:43.421Z\n",
    "               #dth_extracao = time.mktime(datetime.datetime.strptime(ts,\"%Y-%m-%dT%H:%M:%S.%fZ\").timetuple()) # não salvar como unix timestamp, mas sim como datetime\n",
    "\n",
    "               dth_extracao = datetime.datetime.strftime(datetime.datetime.strptime(ts,\"%Y-%m-%dT%H:%M:%S.%fZ\"), \"%Y-%m-%d %H:%M\")\n",
    "               \n",
    "               id_col = (schemas[camada])['id_col'] if 'id_col' in schemas[camada] else '' \n",
    "               idx = 1\n",
    "               for col in schemas[camada].keys():\n",
    "                   if col != 'id_col':\n",
    "                       try:\n",
    "                           # %time dfCol, dfColDePara = trata_coluna(col, id_col, idx, camada, identificador, categoria, prefixo_campo, totalFeatures, numberMatched, numberReturned, dth_extracao)\n",
    "\n",
    "                           dfCol, dfColDePara = trata_coluna(col, id_col, idx, camada, identificador, categoria, prefixo_campo, totalFeatures, numberMatched, numberReturned, dth_extracao)\n",
    "                           \n",
    "                           df = pd.concat([df, dfCol])\n",
    "                           dfDP = pd.concat([dfDP, dfColDePara])\n",
    "                       except Exception as error:\n",
    "                           messages.append(f\"### Erro ao processar {camada} - {col}: {type(error).__name__} – {error} ! ###\")\n",
    "                   idx += 1\n",
    "           break\n",
    "    \n",
    "    dfs[planilha] = df\n",
    "    dfsDP[planilha] = dfDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f661676-9d77-481f-b6d1-c8d258800664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)\n",
    "len(dfsDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10054022-6227-4a3e-b4c3-a53a395769ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_arquivo = f\"{datetime.datetime.now():%Y%m%d_%H%M}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75784ccd-1555-471a-85f7-d627f6ff2c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\General Projects\\Git\\GitHub\\sepep-pmsp\\saade_governancadados/output/20240830_1910_metadados_atributos.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\geopandas\\Lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    }
   ],
   "source": [
    "epath = f\"{ROOT_DIR}/output/{dh_arquivo}_metadados_atributos.xlsx\"\n",
    "print(epath)\n",
    "escreve_excel(dfs, epath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fab1322d-182a-4d0f-93a7-7e0460f13195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\General Projects\\Git\\GitHub\\sepep-pmsp\\saade_governancadados/output/20240830_1910_metadados_v4.xlsx\n"
     ]
    }
   ],
   "source": [
    "# escreve_excel(dfsDP, f\"{dh_arquivo}_metadados_v4.xlsx\")\n",
    "epath = f\"{ROOT_DIR}/output/{dh_arquivo}_metadados_v4.xlsx\"\n",
    "print(epath)\n",
    "escreve_excel(dfsDP, epath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77fba353-5a9d-4565-a632-2d51b836cedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"### Erro ao processar GEOSAMPA_heliponto - ge_ponto: ValueError – You are trying to merge on int64 and object columns for key 'Id'. If you wish to proceed you should use pd.concat ! ###\", \"### Erro ao processar patrimonio_cultural_sitio_arqueologico - ge_ponto: ValueError – You are trying to merge on int64 and object columns for key 'Id'. If you wish to proceed you should use pd.concat ! ###\", \"### Erro ao processar patrimonio_cultural_ocorrencia_arqueologica - ge_ponto: ValueError – You are trying to merge on int64 and object columns for key 'Id'. If you wish to proceed you should use pd.concat ! ###\", \"### Erro ao processar patrimonio_cultural_bem_arqueologico - ge_ponto: ValueError – You are trying to merge on int64 and object columns for key 'Id'. If you wish to proceed you should use pd.concat ! ###\", \"### Erro ao processar patrimonio_cultural_acervo_tombado - ge_ponto: ValueError – You are trying to merge on int64 and object columns for key 'Id'. If you wish to proceed you should use pd.concat ! ###\"]\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1eff5bd-24b5-47d9-a05c-1c4e0a7b3721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento concluído: 30/10</2024 19:08\n"
     ]
    }
   ],
   "source": [
    "print(f\"Processamento concluído: {datetime.datetime.now():%d/%M</%Y %H:%m}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
